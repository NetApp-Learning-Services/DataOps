{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Distilbert\n",
    "\n",
    "This example demonstrates a basic approach to loading model weights from files at initialization time, rather than keeping them in memory as part of the model's state_dict. Some notes on this implementation:\n",
    "\n",
    "* This example only streams the weights of the final classification layer. In a full implementation, you'd want to stream weights for all layers.\n",
    "* The DistilBERT base model weights are still loaded conventionally. For very large models, you'd want to stream all weights.\n",
    "* This approach loads the entire classification layer weights into memory at initialization. For truly large models, you might need to implement more sophisticated streaming mechanisms that load weights in smaller chunks or on-demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.3.1 in /home/user/.local/lib/python3.8/site-packages (2.3.1+cpu)\n",
      "Requirement already satisfied: torchvision==0.18.1 in /home/user/.local/lib/python3.8/site-packages (0.18.1+cpu)\n",
      "Requirement already satisfied: torchaudio==2.3.1 in /home/user/.local/lib/python3.8/site-packages (2.3.1+cpu)\n",
      "Requirement already satisfied: networkx in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: sympy in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (2024.5.0)\n",
      "Requirement already satisfied: filelock in /home/user/.local/lib/python3.8/site-packages (from torch==2.3.1) (3.15.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.18.1) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.8/site-packages (from torchvision==0.18.1) (1.24.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/.local/lib/python3.8/site-packages (from jinja2->torch==2.3.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/user/.local/lib/python3.8/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.41.2 in /home/user/.local/lib/python3.8/site-packages (4.41.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (2024.5.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (4.66.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (0.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.41.2) (5.3.1)\n",
      "Requirement already satisfied: requests in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (2.32.3)\n",
      "Requirement already satisfied: filelock in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/.local/lib/python3.8/site-packages (from transformers==4.41.2) (1.24.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers==4.41.2) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.41.2) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.local/lib/python3.8/site-packages (from requests->transformers==4.41.2) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.41.2) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2024.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy==1.24.4 in /home/user/.local/lib/python3.8/site-packages (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install transformers==4.41.2\n",
    "%pip install numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple streaming model definition\n",
    "\n",
    "The StreamedLinear class represents a linear layer with weights loaded from files:\n",
    "\n",
    "* It uses np.memmap to memory-map the weight and bias files.\n",
    "* It determines the shape of the weight matrix based on the total number of elements and the number of output features (which is the same as the number of bias elements).\n",
    "* The weights and biases are converted to PyTorch tensors and registered as buffers.\n",
    "* The forward method performs a linear operation using these loaded weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamedLinear(nn.Module):\n",
    "    def __init__(self, weight_file, bias_file):\n",
    "        super().__init__()\n",
    "        self.weight_mmap = np.memmap(weight_file, dtype='float32', mode='r')\n",
    "        self.bias_mmap = np.memmap(bias_file, dtype='float32', mode='r')\n",
    "\n",
    "        # Determine shape from the size of the memory-mapped array\n",
    "        # This approach calculates the input features based on the total number of elements in the weight array \n",
    "        # and the number of output features (which is the same as the number of bias elements).\n",
    "        total_elements = self.weight_mmap.size\n",
    "        self.out_features = self.bias_mmap.size\n",
    "        self.in_features = total_elements // self.out_features\n",
    "\n",
    "        # Reshape the weight array\n",
    "        self.weight_mmap = self.weight_mmap.reshape(self.out_features, self.in_features)\n",
    "\n",
    "        # Register buffers for the weights and biases\n",
    "        self.register_buffer(\"weight\", torch.from_numpy(self.weight_mmap[:]).clone())\n",
    "        self.register_buffer(\"bias\", torch.from_numpy(self.bias_mmap[:]).clone())\n",
    "\n",
    "    def forward(self, input):\n",
    "        return nn.functional.linear(input, self.weight, self.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  StreamedDistilBertForSequenceClassification class represents the DistilBERT model for sequence classification:\n",
    "\n",
    "* It initializes the DistilBERT base model normally.\n",
    "* It replaces the classification layer with our StreamedLinear layer.\n",
    "* The forward method processes input through the DistilBERT base, then through the streamed classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamedDistilBertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config, weight_dir):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.weight_dir = weight_dir\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        # Initialize DistilBERT layers (excluding final classification layer)\n",
    "        self.distilbert = DistilBertForSequenceClassification(config).distilbert\n",
    "\n",
    "        # Replace the classification layer with StreamedLinear\n",
    "        weight_file = os.path.join(weight_dir, 'classifier.weight.bin')\n",
    "        bias_file = os.path.join(weight_dir, 'classifier.bias.bin')\n",
    "        self.classifier = StreamedLinear(weight_file, bias_file)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.distilbert(input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = outputs[0]  # (bs, seq_len, dim)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        logits = self.classifier(pooled_output)  # (bs, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions and Setup\n",
    "\n",
    "These functions handle saving and loading model weights:\n",
    "\n",
    "* save_model_weights saves the classification layer weights to binary files and the rest of the model to a PyTorch state dict.\n",
    "* load_streamed_model creates a new streamed model and loads the DistilBERT base weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(model, weight_dir):\n",
    "    os.makedirs(weight_dir, exist_ok=True)\n",
    "    \n",
    "    # Save weights for the classification layer\n",
    "    classifier_weight = model.classifier.weight.detach().numpy()\n",
    "    classifier_bias = model.classifier.bias.detach().numpy()\n",
    "    \n",
    "    classifier_weight.tofile(os.path.join(weight_dir, 'classifier.weight.bin'))\n",
    "    classifier_bias.tofile(os.path.join(weight_dir, 'classifier.bias.bin'))\n",
    "\n",
    "    # Save other layers (in practice, you'd do this for all layers)\n",
    "    torch.save(model.distilbert.state_dict(), os.path.join(weight_dir, 'distilbert_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_streamed_model(config, weight_dir):\n",
    "    model = StreamedDistilBertForSequenceClassification(config, weight_dir)\n",
    "    # Load weights for other layers\n",
    "    model.distilbert.load_state_dict(torch.load(os.path.join(weight_dir, 'distilbert_weights.pth')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Weight Saving\n",
    "\n",
    "First, this code creates a regular DistilBERT model and saves its weights. Next, it loads a streamed version of the model. Finally, it creates a tokenizer for inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Regular model loading time: 2.3865 seconds\n",
      "  Stream model loading time: 2.5489 seconds\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = 2  # Binary classification\n",
    "\n",
    "# Create and save a regular model\n",
    "start_time = time.time()\n",
    "regular_model = DistilBertForSequenceClassification(config)\n",
    "regular_load_time = time.time() - start_time\n",
    "print(f\"  Regular model loading time: {regular_load_time:.4f} seconds\")\n",
    "save_model_weights(regular_model, 'weight_dir')\n",
    "\n",
    "# Load the streamed model\n",
    "start_time = time.time()\n",
    "streamed_model = load_streamed_model(config, 'weight_dir')\n",
    "streamed_load_time = time.time() - start_time\n",
    "print(f\"  Stream model loading time: {streamed_load_time:.4f} seconds\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "This code performs an inference on both the normal model and streaming model and compares their output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular model output: tensor([[0.4382, 0.1866]])\n",
      "  Inference time: 0.1126 seconds\n",
      "  Total time: 2.4990 seconds\n",
      "Streamed model output: tensor([[-0.1210,  0.1469]])\n",
      "  Inference time: 0.1608 seconds\n",
      "  Total time: 2.7098 seconds\n",
      "Outputs are close: False\n",
      "Number of trainable parameters in regular model: 66,955,010\n",
      "Number of trainable parameters in streamed model: 66,362,880\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input\n",
    "text = \"This is an example sentence for inference.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    outputs_regular = regular_model(**inputs).logits\n",
    "    regular_inference_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    outputs_streamed = streamed_model(**inputs)\n",
    "    streamed_inference_time = time.time() - start_time\n",
    "\n",
    "# Print results\n",
    "print(\"Regular model output:\", outputs_regular)\n",
    "print(f\"  Inference time: {regular_inference_time:.4f} seconds\")\n",
    "print(f\"  Total time: {regular_load_time + regular_inference_time:.4f} seconds\")\n",
    "print(\"Streamed model output:\", outputs_streamed)\n",
    "print(f\"  Inference time: {streamed_inference_time:.4f} seconds\")\n",
    "print(f\"  Total time: {streamed_load_time + streamed_inference_time:.4f} seconds\")\n",
    "print(\"Outputs are close:\", torch.allclose(outputs_regular, outputs_streamed, atol=1e-5))\n",
    "\n",
    "# Print number of parameters\n",
    "num_params_regular = sum(p.numel() for p in regular_model.parameters() if p.requires_grad)\n",
    "num_params_streamed = sum(p.numel() for p in streamed_model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters in regular model: {num_params_regular:,}\")\n",
    "print(f\"Number of trainable parameters in streamed model: {num_params_streamed:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key points about this implementation:\n",
    "\n",
    "* It only streams the weights of the final classification layer. The DistilBERT base model weights are still loaded conventionally.\n",
    "* The streamed weights are actually loaded into memory at initialization. For truly large models, you'd need a more sophisticated streaming mechanism.\n",
    "* This approach demonstrates the concept of separating weight storage from the model architecture, which can be extended for larger models.\n",
    "* The number of trainable parameters in the streamed model will be lower because the streamed weights are not considered parameters.\n",
    "\n",
    "Limitations and potential improvements:\n",
    "\n",
    "* Extend streaming to all layers of the model, not just the classification layer.\n",
    "* Implement true streaming where weights are loaded on-demand during forward passes.\n",
    "* Add functionality to stream weights for fine-tuning or updating the model.\n",
    "\n",
    "This example serves as a starting point for implementing weight streaming in neural network models, which can be particularly useful for deploying large language models in memory-constrained environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
