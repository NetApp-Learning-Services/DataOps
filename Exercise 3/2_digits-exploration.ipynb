{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Data Exploration Notebook\n",
    "\n",
    "In this [Kaggle competition](https://www.kaggle.com/competitions/digit-recognizer/overview) \n",
    "\n",
    ">MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    ">In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages\n",
    "\n",
    "We use the requirement.txt file to list all the dependencies and then run pip install for the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --user --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first time running this pip command, restart the kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install graphviz for Keras Visualize to work.  The following is the command to install it.  However, if you are following the labs, this tool has been preinstalled installed in the container hosting this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sudo apt-get install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this section, we import the packages needed in this example.  It is good practice to gather your imports into a single place.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, optimizers\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import layers\n",
    "print(\"tensorflow version: \", tf.__version__)\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "\n",
    "from keras_visualizer import visualizer \n",
    "\n",
    "from netapp_dataops.k8s import clone_volume, create_volume, \\\n",
    "delete_volume, list_volumes, create_volume_snapshot, \\\n",
    "delete_volume_snapshot, list_volume_snapshots, restore_volume_snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Volumes\n",
    "\n",
    "The data exists in 4 volumes with data defined by the data prep notebook (1_digits-dataprep.ipynb):\n",
    "- digits-train\n",
    "- digits-valid\n",
    "- digits-test\n",
    "- digits-prod\n",
    "\n",
    "There is an additional volume for the model:\n",
    "- digits-model\n",
    "\n",
    "These are all mounted at the path represented by DATA_ROOT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/home/jovyan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate a root folder for the data\n",
    "DATA_DIR = 'data'\n",
    "DATA_ROOT = os.path.join(ROOT_DIR, DATA_DIR)\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data paths\n",
    "DATA_TRAIN_PVC = 'digits-train'\n",
    "DATA_TRAIN_ROOT = os.path.join(DATA_ROOT, DATA_TRAIN_PVC)\n",
    "os.makedirs(DATA_TRAIN_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TRAIN_ROOT)\n",
    "DATA_TRAIN_FILE = os.path.join(DATA_TRAIN_ROOT,'train.csv')\n",
    "print(DATA_TRAIN_FILE)\n",
    "assert os.path.exists(DATA_TRAIN_FILE)\n",
    "\n",
    "# Testing data paths\n",
    "DATA_TEST_PVC = 'digits-test'\n",
    "DATA_TEST_ROOT = os.path.join(DATA_ROOT, DATA_TEST_PVC)\n",
    "os.makedirs(DATA_TEST_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TEST_ROOT)\n",
    "DATA_TEST_FILE = os.path.join(DATA_TEST_ROOT,'test.csv')\n",
    "assert os.path.exists(DATA_TEST_FILE)\n",
    "\n",
    "# Validation data paths\n",
    "DATA_VALID_PVC = 'digits-valid'\n",
    "DATA_VALID_ROOT = os.path.join(DATA_ROOT,DATA_VALID_PVC)\n",
    "os.makedirs(DATA_VALID_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_VALID_ROOT)\n",
    "DATA_VALID_FILE = os.path.join(DATA_VALID_ROOT,'valid.csv')\n",
    "assert os.path.exists(DATA_VALID_FILE)\n",
    "\n",
    "# Production data paths\n",
    "DATA_PROD_PVC = 'digits-prod'\n",
    "DATA_PROD_ROOT = os.path.join(DATA_ROOT, DATA_PROD_PVC)\n",
    "os.makedirs(DATA_PROD_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_PROD_ROOT)\n",
    "DATA_PROD_FILE = os.path.join(DATA_PROD_ROOT,'prod.csv')\n",
    "assert os.path.exists(DATA_PROD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model data paths\n",
    "DATA_MODEL_PVC = 'digits-model'\n",
    "DATA_MODEL_ROOT = os.path.join(DATA_ROOT, DATA_MODEL_PVC)\n",
    "os.makedirs(DATA_MODEL_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset into pandas \n",
    "TRAIN_DF = pd.read_csv(DATA_TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top 5 rows of the training data\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial shape of the training data\n",
    "TRAIN_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the image data (_X) from the label (_Y) for the train set\n",
    "TRAIN_X = TRAIN_DF.drop('label', axis=1)\n",
    "TRAIN_Y = TRAIN_DF.label\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)... This is needed for the Keras API\n",
    "TRAIN_X = TRAIN_X.values.reshape(-1,28,28,1)\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "TRAIN_X = TRAIN_X /255.0\n",
    "TRAIN_X.shape, TRAIN_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed for reproducibility and ignore warning messages\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a model using a stack of layers\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Creating 3 layers of a convolution network\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "# Flatting the results\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Creating output\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Most important\n",
    "# Output are 10 classes, numbers from 0-9\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) \n",
    "\n",
    "# Show model summary - how it looks\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PNG_MODEL_FILE = os.path.join(ROOT_DIR,'digits-model')\n",
    "visualizer(model, file_name=PNG_MODEL_FILE, file_format='png', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(PNG_MODEL_FILE+ '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model - we want to have a multiple outcome\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and return the history while training\n",
    "history = model.fit(\n",
    "  x=TRAIN_X,\n",
    "  y=TRAIN_Y,\n",
    "  epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subfolder in the model volume with the datetime stamp\n",
    "now = datetime.now()\n",
    "DATA_MODEL_VERSION = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "DATA_MODEL_VERSION_PATH = os.path.join(DATA_MODEL_ROOT, DATA_MODEL_VERSION)\n",
    "os.makedirs(DATA_MODEL_VERSION_PATH, exist_ok=True)\n",
    "print(\"Path to the model: \" + DATA_MODEL_VERSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model the model volume\n",
    "keras.models.save_model(model, DATA_MODEL_VERSION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model already trained\n",
    "model = keras.models.load_model(DATA_MODEL_VERSION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF = pd.read_csv(DATA_VALID_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilt the training data into so the label is in TRAIN_Y and TRAIN_X doesn't include the label\n",
    "VALID_X = VALID_DF.drop('label', axis=1)\n",
    "VALID_Y = VALID_DF.label\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "VALID_X = VALID_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "VALID_X = VALID_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model against the test dataset\n",
    "# Returns the loss value & metrics values for the model in test mode.\n",
    "model_loss, model_accuracy = model.evaluate(x=VALID_X,y=VALID_Y, verbose=0)\n",
    "print(\"Test_loss: {}, Test_accuracy: {} \".format(model_loss,model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# Generates output predictions for the input samples.\n",
    "test_predictions = model.predict(x=VALID_X)\n",
    "\n",
    "# Returns the indices of the maximum values along an axis.\n",
    "test_predictions = np.argmax(test_predictions,axis=1) # the prediction outputs 10 values, we take the index number of the highest value, which is the prediction of the model\n",
    "\n",
    "# generate confusion matrix\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=VALID_Y,predictions=test_predictions)\n",
    "\n",
    "# plot confusion matrix\n",
    "h = sns.heatmap(confusion_matrix, fmt='g', cbar=False, annot=True,cmap='Blues')\n",
    "h.set(xlabel='Predicted', ylabel='Actual', title=\"Confusion Matrix\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a snapshot of the model volume\n",
    "\n",
    "Creating a snapshot of the model volume, allows for protection and also cloning of the volume in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAMESPACE = \"kubeflow-user-example-com\"\n",
    "DATA_MODEL_SNAP = 'digits-model-snap-' + DATA_MODEL_VERSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VolumeSnapshot for the volume attached to the \n",
    "#   PersistentVolumeClaim (PVC) named in the variable DATA_MODEL_PVC in namespace in USER_NAMESPACE.\n",
    "#   NOTE: if snapshotName is not specified, the snapshot name will be set to 'ntap-dsutil.<timestamp>\n",
    "create_volume_snapshot(pvc_name=DATA_MODEL_PVC, namespace=USER_NAMESPACE, snapshot_name=DATA_MODEL_SNAP, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the VolumeSnapshots for the namespace\n",
    "list_volume_snapshots(namespace=USER_NAMESPACE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaec0c28839895f25e5089594964594e0b9ed4fc5fb3afe9a385b1f40747c44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
