{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Data Exploration Notebook\n",
    "\n",
    "In this [Kaggle competition](https://www.kaggle.com/competitions/digit-recognizer/overview) \n",
    "\n",
    ">MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    ">In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages\n",
    "\n",
    "We use the requirement.txt file to list all the dependencies and then run pip install for the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --user --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first time running this file, restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sudo apt-get install graphviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this section, we import the packages needed in this example.  It is good practice to gather your imports into a single place.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, optimizers\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import layers\n",
    "print(\"tensorflow version: \", tf.__version__)\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "\n",
    "from keras_visualizer import visualizer \n",
    "\n",
    "from netapp_dataops.k8s import cloneJupyterLab, createJupyterLab, deleteJupyterLab, \\\n",
    "listJupyterLabs, createJupyterLabSnapshot, listJupyterLabSnapshots, restoreJupyterLabSnapshot, \\\n",
    "cloneVolume, createVolume, deleteVolume, listVolumes, createVolumeSnapshot, \\\n",
    "deleteVolumeSnapshot, listVolumeSnapshots, restoreVolumeSnapshot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Volumes\n",
    "\n",
    "The data exists in 4 volumes with data defined by the data prep notebook (1_digits-dataprep.ipynb):\n",
    "- digits-train\n",
    "- digits-valid\n",
    "- digits-test\n",
    "- digits-prod\n",
    "\n",
    "There is an additional volume for the model:\n",
    "- digits-model\n",
    "\n",
    "These are all mounted at the path represented by DATA_ROOT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate a root folder for the data\n",
    "DATA_ROOT = '/data'\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data paths\n",
    "DATA_TRAIN_PVC = 'digits-train'\n",
    "DATA_TRAIN_ROOT = os.path.join(DATA_ROOT, DATA_TRAIN_PVC)\n",
    "os.makedirs(DATA_TRAIN_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TRAIN_ROOT)\n",
    "DATA_TRAIN_FILE = os.path.join(DATA_TRAIN_ROOT,'train.csv')\n",
    "assert os.path.exists(DATA_TRAIN_FILE)\n",
    "\n",
    "# Testing data paths\n",
    "DATA_TEST_PVC = 'digits-test'\n",
    "DATA_TEST_ROOT = os.path.join(DATA_ROOT, DATA_TEST_PVC)\n",
    "os.makedirs(DATA_TEST_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TEST_ROOT)\n",
    "DATA_TEST_FILE = os.path.join(DATA_TEST_ROOT,'test.csv')\n",
    "assert os.path.exists(DATA_TEST_FILE)\n",
    "\n",
    "# Validation data paths\n",
    "DATA_VALID_PVC = 'digits-valid'\n",
    "DATA_VALID_ROOT = os.path.join(DATA_ROOT,DATA_VALID_PVC)\n",
    "os.makedirs(DATA_VALID_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_VALID_ROOT)\n",
    "DATA_VALID_FILE = os.path.join(DATA_VALID_ROOT,'valid.csv')\n",
    "assert os.path.exists(DATA_VALID_FILE)\n",
    "\n",
    "# Production data paths\n",
    "DATA_PROD_PVC = 'digits-prod'\n",
    "DATA_PROD_ROOT = os.path.join(DATA_ROOT, DATA_PROD_PVC)\n",
    "os.makedirs(DATA_PROD_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_PROD_ROOT)\n",
    "DATA_PROD_FILE = os.path.join(DATA_PROD_ROOT,'prod.csv')\n",
    "assert os.path.exists(DATA_PROD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model data paths\n",
    "DATA_MODEL_PVC = 'model'\n",
    "DATA_MODEL_ROOT = os.path.join(DATA_ROOT, DATA_MODEL_PVC)\n",
    "os.makedirs(DATA_MODEL_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_MODEL_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the data volumes\n",
    "We will not touch the original volumes but instead will work with cloned volumes only.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAMESPACE = \"kubeflow-user-example-com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New persistentvolumeclaims names for the clone volumes\n",
    "CLONE_TRAIN_PVC = 'digits-train-clone' \n",
    "CLONE_VALID_PVC = 'digits-valid-clone'\n",
    "CLONE_TEST_PVC = 'digits-test-clone'\n",
    "CLONE_PROD_PVC = 'digits-prod-clone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the training volume \n",
    "# in the USER_NAMESPACE namespace and create a new persistentvolumeclaim\n",
    "cloneVolume --source-pvc-name=DATA_TRAIN_PVC --new-pvc-name=CLONE_TRAIN_PVC --namespace=USER_NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount the new clone volume under the DATA_ROOT\n",
    "dsl.ContainerOp(name='Mount clone', pvolumes={DATA_ROOT: dsl.PipelineVolume(pvc=\"train_clone\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the validation volume \n",
    "# in the USER_NAMESPACE namespace and create a new persistentvolumeclaim\n",
    "#cloneVolume  --source-pvc-name=DATA_VALID_PVC --new-pvc-name=CLONE_VALID_PVC --namespace=USER_NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the test volume \n",
    "# in the USER_NAMESPACE namespace and create a new persistentvolumeclaim\n",
    "#cloneVolume  --source-pvc-name=DATA_TEST_PVC --new-pvc-name=CLONE_TEST_PVC --namespace=USER_NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the production volume \n",
    "# in the USER_NAMESPACE namespace and create a new persistentvolumeclaim\n",
    "#cloneVolume  --source-pvc-name=DATA_PROD_PVC --new-pvc-name=CLONE_PROD_PVC --namespace=USER_NAMESPACE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset into pandas \n",
    "TRAIN_DF = pd.read_csv(DATA_TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top 5 rows of the training data\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial shape of the training data\n",
    "TRAIN_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the image data (_X) from the label (_Y) for the train set\n",
    "TRAIN_X = TRAIN_DF.drop('label', axis=1)\n",
    "TRAIN_Y = TRAIN_DF.label\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)... This is needed for the Keras API\n",
    "TRAIN_X = TRAIN_X.values.reshape(-1,28,28,1)\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "TRAIN_X = TRAIN_X /255.0\n",
    "TRAIN_X.shape, TRAIN_Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed for reproducibility and ignore warning messages\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a model using a stack of layers\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Creating 3 layers of a convolution network\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "# Flatting the results\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Creating output\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Most important\n",
    "# Output are 10 classes, numbers from 0-9\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) \n",
    "\n",
    "# Show model summary - how it looks\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PNG_MODEL_FILE = os.path.join(DATA_ROOT,'digits-model')\n",
    "visualizer(model, file_name=PNG_MODEL_FILE, file_format='png', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(PNG_MODEL_FILE+ '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model - we want to have a multiple outcome\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and return the history while training\n",
    "history = model.fit(\n",
    "  x=TRAIN_X,\n",
    "  y=TRAIN_Y,\n",
    "  epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model the model volume\n",
    "keras.models.save_model(model, DATA_MODEL_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if already trained\n",
    "model = keras.models.load_model(DATA_MODEL_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF = pd.read_csv(DATA_VALID_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilt the training data into so the label is in TRAIN_Y and TRAIN_X doesn't include the label\n",
    "VALID_X = VALID_DF.drop('label', axis=1)\n",
    "VALID_Y = VALID_DF.label\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "VALID_X = VALID_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "VALID_X = VALID_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model against the test dataset\n",
    "# Returns the loss value & metrics values for the model in test mode.\n",
    "model_loss, model_accuracy = model.evaluate(x=VALID_X,y=VALID_Y, verbose=0)\n",
    "print(\"Test_loss: {}, Test_accuracy: {} \".format(model_loss,model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# Generates output predictions for the input samples.\n",
    "test_predictions = model.predict(x=VALID_X)\n",
    "\n",
    "# Returns the indices of the maximum values along an axis.\n",
    "test_predictions = np.argmax(test_predictions,axis=1) # the prediction outputs 10 values, we take the index number of the highest value, which is the prediction of the model\n",
    "\n",
    "# generate confusion matrix\n",
    "confusion_matrix = tf.math.confusion_matrix(labels=VALID_Y,predictions=test_predictions)\n",
    "\n",
    "# plot confusion matrix\n",
    "h = sns.heatmap(confusion_matrix, fmt='g', cbar=False, annot=True,cmap='Blues')\n",
    "h.set(xlabel='Predicted', ylabel='Actual', title=\"Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaec0c28839895f25e5089594964594e0b9ed4fc5fb3afe9a385b1f40747c44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
