{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Data Preparation Notebook\n",
    "\n",
    "In this [Kaggle competition](https://www.kaggle.com/competitions/digit-recognizer/overview) \n",
    "\n",
    ">MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    ">In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages\n",
    "\n",
    "We use the requirement.txt file to list all the dependencies and then run pip install for the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -r requirements.txt --user --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first time running this pip command, restart the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this section, we import the packages needed in this example.  It is good practice to gather your imports into a single place.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "from netapp_dataops.k8s import clone_volume, create_volume, \\\n",
    "delete_volume, list_volumes, create_volume_snapshot, \\\n",
    "delete_volume_snapshot, list_volume_snapshots, restore_volumesnapshot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "- Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. \n",
    "- Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_ZIP = 'train.csv.zip'\n",
    "TEST_CSV_ZIP = 'test.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/home/jovyan'\n",
    "assert os.path.exists(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/jovyan/data'\n",
    "assert os.path.exists(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data paths\n",
    "DATA_TRAIN_PVC = 'digits-train'\n",
    "DATA_TRAIN_ROOT = os.path.join(DATA_ROOT, DATA_TRAIN_PVC)\n",
    "os.makedirs(DATA_TRAIN_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TRAIN_ROOT)\n",
    "DATA_TRAIN_FILE = os.path.join(DATA_TRAIN_ROOT,'train.csv')\n",
    "\n",
    "# Testing data paths\n",
    "DATA_TEST_PVC = 'digits-test'\n",
    "DATA_TEST_ROOT = os.path.join(DATA_ROOT, DATA_TEST_PVC)\n",
    "os.makedirs(DATA_TEST_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_TEST_ROOT)\n",
    "DATA_TEST_FILE = os.path.join(DATA_TEST_ROOT,'test.csv')\n",
    "\n",
    "# Validation data paths\n",
    "DATA_VALID_PVC = 'digits-valid'\n",
    "DATA_VALID_ROOT = os.path.join(DATA_ROOT,DATA_VALID_PVC)\n",
    "os.makedirs(DATA_VALID_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_VALID_ROOT)\n",
    "DATA_VALID_FILE = os.path.join(DATA_VALID_ROOT,'valid.csv')\n",
    "\n",
    "# Production data paths\n",
    "DATA_PROD_PVC = 'digits-prod'\n",
    "DATA_PROD_ROOT = os.path.join(DATA_ROOT, DATA_PROD_PVC)\n",
    "os.makedirs(DATA_PROD_ROOT, exist_ok=True)\n",
    "assert os.path.exists(DATA_PROD_ROOT)\n",
    "DATA_PROD_FILE = os.path.join(DATA_PROD_ROOT,'prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('train.csv.zip', 'r') as zip:\n",
    "    zip.extractall(ROOT)\n",
    "zip.close()\n",
    "RAW_TRAIN_ROOT = os.path.join(ROOT,'train.csv')\n",
    "assert os.path.exists(RAW_TRAIN_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into two parts\n",
    "# 75% for training\n",
    "# 25% for (cross)validation\n",
    "RAW_TRAIN_DF1 = pd.read_csv(RAW_TRAIN_ROOT)\n",
    "PART_75 = RAW_TRAIN_DF1.sample(frac =0.75)\n",
    "PART_25 = RAW_TRAIN_DF1.drop(PART_75.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split data sets to files\n",
    "PART_75.to_csv(DATA_TRAIN_FILE, encoding='utf-8', index=False)\n",
    "PART_25.to_csv(DATA_VALID_FILE, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(TEST_CSV_ZIP, 'r') as zip:\n",
    "    zip.extractall(ROOT)\n",
    "zip.close()\n",
    "\n",
    "RAW_TEST_ROOT = os.path.join(ROOT,'test.csv')\n",
    "assert os.path.exists(RAW_TEST_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test.csv into 2 parts\n",
    "# 50% for Test\n",
    "# 50% for Prod\n",
    "RAW_TEST_DF1 = pd.read_csv(RAW_TEST_ROOT)\n",
    "PART_50 = RAW_TEST_DF1.sample(frac =0.5)\n",
    "PART_50_2 = RAW_TEST_DF1.drop(PART_50.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split data sets to files\n",
    "PART_50.to_csv(DATA_TEST_FILE, encoding='utf-8', index=False)\n",
    "PART_50_2.to_csv(DATA_PROD_FILE, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset into pandas \n",
    "TRAIN_DF = pd.read_csv(DATA_TRAIN_FILE)\n",
    "TEST_DF = pd.read_csv(DATA_TEST_FILE)\n",
    "EVAL_DF = pd.read_csv(DATA_VALID_FILE)\n",
    "PROD_DF = pd.read_csv(DATA_PROD_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now explore the data\n",
    "To this end, we use the pandas `head` method to visualize the 1st five rows of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilt the training data into so the label is in TRAIN_Y and TRAIN_X doesn't include the label\n",
    "TRAIN_X = TRAIN_DF.drop('label', axis=1)\n",
    "TRAIN_Y = TRAIN_DF.label\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "TRAIN_X = TRAIN_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "TRAIN_X = TRAIN_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single data instances\n",
    "\n",
    "img_no = 31499 # Change the number to display other examples\n",
    "\n",
    "first_number = TRAIN_X[img_no]\n",
    "plt.imshow(first_number, cmap='gray') # Visualize the numbers in gray mode\n",
    "plt.show()\n",
    "print(f\"correct number: {TRAIN_Y[img_no]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilt the training data into so the label is in TRAIN_Y and TRAIN_X doesn't include the label\n",
    "EVAL_X = EVAL_DF.drop('label', axis=1)\n",
    "EVAL_Y = EVAL_DF.label\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "EVAL_X = EVAL_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "EVAL_X = EVAL_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single data instances\n",
    "\n",
    "img_no = 10499 # Change the number to display other examples\n",
    "\n",
    "first_number = EVAL_X[img_no]\n",
    "plt.imshow(first_number, cmap='gray') # Visualize the numbers in gray mode\n",
    "plt.show()\n",
    "print(f\"correct number: {EVAL_Y[img_no]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_X = TEST_DF\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "TEST_X = TEST_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "TEST_X = TEST_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single data instances\n",
    "\n",
    "img_no = 13999 # Change the number to display other examples\n",
    "\n",
    "first_number = TEST_X[img_no]\n",
    "plt.imshow(first_number, cmap='gray') # Visualize the numbers in gray mode\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_X = PROD_DF\n",
    "\n",
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "PROD_X = PROD_X.values.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "PROD_X = PROD_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single data instances\n",
    "\n",
    "img_no = 13999 # Change the number to display other examples\n",
    "\n",
    "first_number = PROD_X[img_no]\n",
    "plt.imshow(first_number, cmap='gray') # Visualize the numbers in gray mode\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Snapshots of the 4 Data Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAMESPACE = \"kubeflow-user-example-com\"\n",
    "DATA_TRAIN_SNAP = 'digits-train-snap'\n",
    "DATA_TEST_SNAP = 'digits-test-snap'\n",
    "DATA_VALID_SNAP = 'digits-valid-snap'\n",
    "DATA_PROD_SNAP = 'digits-prod-snap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VolumeSnapshot for the volume attached to the \n",
    "#   PersistentVolumeClaim (PVC) named in the variable DATA_TRAIN_PVC in namespace in USER_NAMESPACE.\n",
    "#   NOTE: if snapshotName is not specified, the snapshot name will be set to 'ntap-dsutil.<timestamp>\n",
    "create_volume_snapshot(pvc_name=DATA_TRAIN_PVC, namespace=USER_NAMESPACE, snapshot_name=DATA_TRAIN_SNAP, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VolumeSnapshot for the volume attached to the \n",
    "#   PersistentVolumeClaim (PVC) named in the variable DATA_TEST_PVC in namespace in USER_NAMESPACE.\n",
    "#   NOTE: if snapshotName is not specified, the snapshot name will be set to 'ntap-dsutil.<timestamp>\n",
    "create_volume_snapshot(pvc_name=DATA_TEST_PVC, namespace=USER_NAMESPACE, snapshot_name=DATA_TEST_SNAP, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VolumeSnapshot for the volume attached to the \n",
    "#   PersistentVolumeClaim (PVC) named in the variable DATA_VALID_PVC in namespace in USER_NAMESPACE.\n",
    "#   NOTE: if snapshotName is not specified, the snapshot name will be set to 'ntap-dsutil.<timestamp>\n",
    "create_volume_snapshot(pvc_name=DATA_VALID_PVC, namespace=USER_NAMESPACE, snapshot_name=DATA_VALID_SNAP, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VolumeSnapshot for the volume attached to the \n",
    "#   PersistentVolumeClaim (PVC) named in the variable DATA_PROD_PVC in namespace in USER_NAMESPACE.\n",
    "#   NOTE: if snapshotName is not specified, the snapshot name will be set to 'ntap-dsutil.<timestamp>\n",
    "create_volume_snapshot(pvc_name=DATA_PROD_PVC, namespace=USER_NAMESPACE, snapshot_name=DATA_PROD_SNAP, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the VolumeSnapshots for the namespace\n",
    "list_volume_snapshots(namespace=USER_NAMESPACE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaec0c28839895f25e5089594964594e0b9ed4fc5fb3afe9a385b1f40747c44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
